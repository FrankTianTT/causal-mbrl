from omegaconf import DictConfig

cfg = DictConfig(
    {
        "algorithm": {
            "name": "off_dyna",
            "freq_train_model": "${task.freq_train_model}",
            "real_data_ratio": 0.0,
            "sac_samples_action": True,
            "num_eval_episodes": 5,
            "dataset_size": 1000000,
            "penalty_coeff": "${task.penalty_coeff}",
            "agent": {
                "_target_": "stable_baselines3.sac.SAC",
                "policy": "MlpPolicy",
                "env": {
                    "_target_": "cmrl.models.fake_env.VecFakeEnv",
                    "num_envs": 16,
                    "action_space": {"_target_": "gym.spaces.Box", "low": "???", "high": "???", "shape": "???"},
                    "observation_space": {"_target_": "gym.spaces.Box", "low": "???", "high": "???", "shape": "???"},
                },
                "learning_starts": 0,
                "batch_size": 256,
                "tau": 0.005,
                "gamma": 0.99,
                "ent_coef": "auto",
                "target_entropy": "auto",
                "verbose": 0,
                "seed": "${seed}",
                "device": "${device}",
            },
        },
        "dynamics": {
            "name": "constraint_based_dynamics",
            "multi_step": "${task.multi_step}",
            "transition": {
                "_target_": "cmrl.models.transition.ExternalMaskEnsembleGaussianTransition",
                "obs_size": "???",
                "action_size": "???",
                "deterministic": False,
                "ensemble_num": "${task.ensemble_num}",
                "elite_num": "${task.elite_num}",
                "residual": True,
                "learn_logvar_bounds": False,
                "num_layers": 4,
                "hid_size": 200,
                "activation_fn_cfg": {"_target_": "torch.nn.SiLU"},
                "device": "${device}",
            },
            "learned_reward": "${task.learning_reward}",
            "reward_mech": {"_target_": "cmrl.models.BaseRewardMech", "obs_size": "???", "action_size": "???"},
            "learned_termination": "${task.learning_terminal}",
            "termination_mech": {"_target_": "cmrl.models.BaseTerminationMech", "obs_size": "???", "action_size": "???"},
            "optim_lr": "${task.optim_lr}",
            "weight_decay": "${task.weight_decay}",
            "patience": "${task.patience}",
            "batch_size": "${task.batch_size}",
            "use_ratio": "${task.use_ratio}",
            "validation_ratio": "${task.validation_ratio}",
            "shuffle_each_epoch": "${task.shuffle_each_epoch}",
            "bootstrap_permutes": "${task.bootstrap_permutes}",
            "longest_epoch": "${task.longest_epoch}",
            "improvement_threshold": "${task.improvement_threshold}",
            "normalize": True,
            "normalize_double_precision": True,
        },
        "task": {
            "env": "emei___BoundaryInvertedPendulumSwingUp-v0___"
            "freq_rate=${task.freq_rate}&time_step=${task.time_step}___${task.dataset}",
            "dataset": "SAC-expert-replay",
            "freq_rate": 1,
            "time_step": 0.02,
            "num_steps": 1000,
            "online_num_steps": 10000,
            "epoch_length": 10000,
            "n_eval_episodes": 8,
            "eval_freq": 100,
            "learning_reward": False,
            "learning_terminal": False,
            "ensemble_num": 7,
            "elite_num": 5,
            "multi_step": "none",
            "oracle": True,
            "cit_threshold": 0.02,
            "test_freq": 100,
            "update_causal_mask_ratio": 0.25,
            "discovery_schedule": [1, 30, 250, 250],
            "penalty_coeff": 0.5,
            "use_ratio": 0.01,
            "freq_train_model": 100,
            "patience": 20,
            "optim_lr": 0.0001,
            "weight_decay": 1e-05,
            "batch_size": 256,
            "validation_ratio": 0.2,
            "shuffle_each_epoch": True,
            "bootstrap_permutes": False,
            "longest_epoch": 10,
            "improvement_threshold": 0.01,
            "effective_model_rollouts_per_step": 50,
            "rollout_schedule": [1, 15, 1, 1],
            "num_sac_updates_per_step": 1,
            "sac_updates_every_steps": 1,
            "num_epochs_to_retain_sac_buffer": 1,
            "sac_gamma": 0.99,
            "sac_tau": 0.005,
            "sac_alpha": 0.2,
            "sac_policy": "Gaussian",
            "sac_target_update_interval": 1,
            "sac_automatic_entropy_tuning": True,
            "sac_hidden_size": 256,
            "sac_lr": 0.0003,
            "sac_batch_size": 256,
            "sac_target_entropy": -1,
        },
        "seed": 0,
        "device": "cpu",
        "exp_name": "default",
        "wandb": False,
    }
)
